# text2code
Code Generation from Natural Language descriptions

## Dataset Used
[CodeSearchNet](https://github.com/github/CodeSearchNet): A dataset designed for training code generation models.

## Implementations

1. **Seq2Seq**
   - Basic sequence-to-sequence model for converting natural language descriptions to code.

2. **Seq2Seq with Attention**
   - Enhanced sequence-to-sequence model with attention mechanism, allowing the model to focus on different parts of the input sequence during decoding.

3. **FineTuning T5small**
   - Fine-tuned implementation using the T5small model, leveraging pre-trained language representations for code generation task.
